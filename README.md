# [CUDA Learning]

Date Created: July 12, 2024 9:40 AM
Status: ç ”ç©¶

# CUDA Intro-tutorial

> ä¸»è¦å‚è€ƒäº†PaddleJITLabçš„Introææ–™ï¼š[CUDATutorial | Notebook (keter.top)](https://cuda.keter.top/)ï¼Œä½œè€…è¿˜æœ‰ä¸€äº›å…¶ä»–çš„Blog: [Aurelius84 - åšå®¢å›­ (cnblogs.com)](https://www.cnblogs.com/CocoML)
> 

### 0. Setup Environment

```jsx
(opensora) zhaotianchen@is-c7bbldidqx6mb3fj-devmachine-0:~$ nvcc -V
nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2023 NVIDIA Corporation
Built on Tue_Aug_15_22:02:13_PDT_2023
Cuda compilation tools, release 12.2, V12.2.140
Build cuda_12.2.r12.2/compiler.33191640_0

---
(opensora) zhaotianchen@is-c7bbldidqx6mb3fj-devmachine-0:~$ g++ --version
g++ (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Copyright (C) 2019 Free Software Foundation, Inc.
This is free software; see the source for copying conditions.  There is NO
warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.
```

- æµ‹è¯•å‘½ä»¤æ”¾åœ¨infini-ztc-1ï¼› `~/project/cuda_learning/`

```jsx
nvcc hello_world.cu -o hello_world
```

### 1. Simple VecSum Example

- CPU Example: `vec_sum_cpu.cpp`
    - åˆ†é…å†…å­˜  `static_cast<float*>(malloc(mem_size))`
        - æ„å‘³ç€é¦–å…ˆä½¿ç”¨`malloc`åˆ†é…å†…å­˜ï¼Œç„¶åå°†è¿”å›çš„`void*`æŒ‡é’ˆè½¬æ¢ä¸º`float*`ç±»å‹ï¼Œä»¥ä¾¿å¯ä»¥å°†å…¶ä½œä¸ºæµ®ç‚¹æ•°æ•°ç»„æ¥ä½¿ç”¨
        - **static_cast<float*>**: è¿™æ˜¯C++ä¸­çš„ç±»å‹è½¬æ¢æ“ä½œç¬¦ï¼Œç”¨äºå°†ä¸€ä¸ªæŒ‡é’ˆè½¬æ¢æˆå¦ä¸€ç§ç±»å‹çš„æŒ‡é’ˆã€‚`static_cast`ä¸ä¼šè¿›è¡Œä»»ä½•ç±»å‹çš„æ£€æŸ¥æˆ–è½¬æ¢ï¼Œå®ƒåªæ˜¯å‘Šè¯‰ç¼–è¯‘å™¨å°†ä¸€ä¸ªæŒ‡é’ˆçš„ç±»å‹è½¬æ¢ä¸ºå¦ä¸€ä¸ªæŒ‡é’ˆçš„ç±»å‹ã€‚åœ¨è¿™ä¸ªä¾‹å­ä¸­ï¼Œå®ƒå°†`malloc`è¿”å›çš„`void*`æŒ‡é’ˆè½¬æ¢ä¸º`float*`ç±»å‹ï¼Œå³æŒ‡å‘`float`çš„æŒ‡é’ˆã€‚

```jsx
g++ vec_sum_cpu.cpp -o vec_sum_cpu
```

- GPU Example: `vec_sum_gpu`
    - GPUä¸Šçš„å‡½æ•°æ·»åŠ  __**global__**ä¿®é¥°ç¬¦å·
    - `<<<M,T>>>` åœ¨Hostç«¯å¯åŠ¨CUDAç¨‹åºçš„å½¢å¼ï¼ŒMè¡¨ç¤ºä¸€ä¸ªgridçš„blockæ•°ç›®ï¼ŒTè¡¨ç¤ºä¸€ä¸ªblokcå¹¶è¡Œçš„threadæ•°ç›®ï¼š
        - `add_kernel<<<1, 1>>>(cuda_x, cuda_y, cuda_out, N);`
    - `cudaMalloc((*void***)&cuda_x, mem_size);`
        - å¯¹åº”æ–‡æ¡£ä¸­çš„è¯´æ˜ï¼š`__host____device__[cudaError_t](https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6)Â [cudaMalloc](https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g37d37965bfb4803b6d4e59ff26856356)Â (void**Â devPtr, size_tÂ sizeÂ )`   Allocate memory on the device.
    - **å†…å­˜é‡Šæ”¾**: ä½¿ç”¨ `cudaMalloc` åˆ†é…çš„å†…å­˜éœ€è¦ä½¿ç”¨ `cudaFree` å‡½æ•°æ¥é‡Šæ”¾ï¼Œä»¥é¿å…**å†…å­˜æ³„æ¼**ã€‚

### 2. NVProf(Nsys) ç®€å•Profile Kernelæ€§èƒ½

- ä¼¼ä¹åœ¨æœ€æ–°çš„ç‰ˆæœ¬nvprofå·²ç»ä¸æ”¯æŒäº†ï¼Œå¯¹äºcompute capabilityè¾ƒé«˜çš„æ–°æœºå™¨â€¦

```jsx
nvprof ./vec_sum_gpu
```

```jsx

======== Warning: nvprof is not supported on devices with compute capability 8.0 and higher.
                  Use NVIDIA Nsight Systems for GPU tracing and CPU sampling and NVIDIA Nsight Compute for GPU profiling.
                  Refer https://developer.nvidia.com/tools-overview for more details.
```

- æ”¹ç”¨nsysï¼Œä¹Ÿæ”¯æŒå‘½ä»¤è¡Œæ‰§è¡Œï¼Œèƒ½æ¶µç›–ä¹‹å‰nvprofçš„åŠŸèƒ½ï¼š
    - åœ¨ `~/project/profiling`ä¸­æœ‰ä¸‹è½½å¥½çš„Nsightçš„dpkgï¼Œå®‰è£…åå¯ç”¨nsysè°ƒç”¨
    - æ›´å¤šçš„å‘½ä»¤è¡ŒåŠŸèƒ½  `nsys profile â€”help`
        - [User Guide â€” nsight-systems 2024.4 documentation (nvidia.com)](https://docs.nvidia.com/nsight-systems/UserGuide/index.html)
    - ç›®å‰çš„profileæ–¹å¼  `nsys profile â€”stats=true ./vec_sum_gpu`
        - ä¼¼ä¹nsysæä¾›äº†ä¸€ç§å…¼å®¹è€ç‰ˆæœ¬nvprof commandçš„å­å‘½ä»¤ `nsys nvprof ./vec_sum_gpu` å¯ä»¥ç»™å‡ºç±»ä¼¼çš„ç»“æœã€‚
        - cuda apiçš„è°ƒç”¨å¼€é”€ï¼šç»å¤§å¤šæ•°æ—¶é—´åœ¨ç­‰å€™cudaMemCpy & cudaMealloc
    
    ```jsx
    [5/8] Executing 'cuda_api_sum' stats report
    
     Time (%)  Total Time (ns)  Num Calls    Avg (ns)      Med (ns)    Min (ns)    Max (ns)     StdDev (ns)            Name
     --------  ---------------  ---------  -------------  -----------  ---------  -----------  -------------  ----------------------
         82.3      732,084,456          3  244,028,152.0  3,793,482.0  3,721,923  724,569,051  416,160,627.6  cudaMemcpy
         17.6      156,475,117          3   52,158,372.3    176,494.0    149,619  156,149,004   90,058,529.8  cudaMalloc
          0.1          452,890          3      150,963.3    108,418.0    102,467      242,005       78,900.5  cudaFree
          0.0          204,640          1      204,640.0    204,640.0    204,640      204,640            0.0  cudaLaunchKernel
          0.0           17,775          1       17,775.0     17,775.0     17,775       17,775            0.0  cudaDeviceSynchronize
          0.0            2,668          1        2,668.0      2,668.0      2,668        2,668            0.0  cuModuleGetLoadingMode
    ```
    
    - cuda Kernelçš„å¼€é”€
    
    ```jsx
    [6/8] Executing 'cuda_gpu_kern_sum' stats report
     Time (%)  Total Time (ns)  Instances    Avg (ns)       Med (ns)      Min (ns)     Max (ns)    StdDev (ns)                     Name
     --------  ---------------  ---------  -------------  -------------  -----------  -----------  -----------  ------------------------------------------
        100.0      704,725,249          1  704,725,249.0  704,725,249.0  704,725,249  704,725,249          0.0  add_kernel(float *, float *, float *, int)
    
    [7/8] Executing 'cuda_gpu_mem_time_sum' stats report
     Time (%)  Total Time (ns)  Count    Avg (ns)      Med (ns)     Min (ns)    Max (ns)   StdDev (ns)           Operation
     --------  ---------------  -----  ------------  ------------  ----------  ----------  -----------  ----------------------------
         72.4       19,244,480      1  19,244,480.0  19,244,480.0  19,244,480  19,244,480          0.0  [CUDA memcpy Device-to-Host]
         27.6        7,342,076      2   3,671,038.0   3,671,038.0   3,644,622   3,697,454     37,357.9  [CUDA memcpy Host-to-Device]
    ```
    
    - Memory(time/size)
    
    ```jsx
    [8/8] Executing 'cuda_gpu_mem_size_sum' stats report
    
     Total (MB)  Count  Avg (MB)  Med (MB)  Min (MB)  Max (MB)  StdDev (MB)           Operation
     ----------  -----  --------  --------  --------  --------  -----------  ----------------------------
         80.000      2    40.000    40.000    40.000    40.000        0.000  [CUDA memcpy Host-to-Device]
         40.000      1    40.000    40.000    40.000    40.000        0.000  [CUDA memcpy Device-to-Host]
    
    ```
    

### 3. å¤šçº¿ç¨‹æ ·ä¾‹ï¼šå¹¶è¡Œè®¡ç®—å‘é‡å’Œ

- å°†ä¸Šé¢ `<<<1,1>>>`çš„kernelæ”¹ä¸ºå¤šçº¿ç¨‹ç‰ˆæœ¬ï¼Œå¹¶è¡Œå¤šä¸ªthreadè¿›è¡Œè®¡ç®—
    - æ”¹å†™åœ¨äº† `vec_sum_gpu_T256.cu` ä¸­
- CUDAæä¾›äº†**å†…å»ºå˜é‡**æ¥è®¿é—®æ¯ä¸ªthreadçš„ç›¸å…³ä¿¡æ¯ï¼ˆåœ¨æŸä¸ªGridä¸­ç´¢å¼•çº¿ç¨‹ï¼‰ï¼š
    - `threadIdx.x`: æŒ‡æ­¤çº¿ç¨‹åœ¨`thread block`ä¸­çš„ä¸‹æ ‡ä½ç½®
    - `blockDim.x`: æŒ‡ä¸€ä¸ª`thread block`ä¸­çš„çº¿ç¨‹æ•°
- è‹¥è¦å°†æŸä¸ªè®¡ç®—workloadï¼Œåˆ‡åˆ†åˆ°256ä¸ªçº¿ç¨‹ä¸­è¿›è¡Œè®¡ç®—ï¼Œå¯è®¾ç½®strideï¼š
    - è¯»â€å½“å‰çš„threadâ€œåœ¨blockä¸­çš„ä¸‹æ ‡ä½ç½®ï¼Œä»¥blockä¸­çš„threadä¸ªæ•°ä¸ºstrideï¼ˆåœ¨å¤–é¢add_kernelçš„ä¹‹åæ”¹æˆ `<<<1,256>>>`ï¼Œè°ƒç”¨ä¸€ä¸ªblockï¼Œblockä¸­æœ‰256ä¸ªthreadï¼‰
    
    ```jsx
    __global__ void add_kernel(float *x, float *y, float *out, int n){
        int index = threadIdx.x;  // å½“å‰çº¿ç¨‹æ‰€åœ¨çš„ä¸‹æ ‡ä½ç½®
        int stride = blockDim.x;  // æ­¤æ ·ä¾‹ä¸­ä¸º 256ï¼Œç”±<<<1, 256>>>è‡ªåŠ¨ä¼ é€’è¿‡æ¥
    
        for (int i = index; i < n; i += stride) {
            out[i] = x[i] + y[i];
        }
    }
    ```
    
    ![Untitled](%5BCUDA%20Learning%5D%20fe71681b7adc4709871b2af69c765163/Untitled.png)
    

![Untitled](%5BCUDA%20Learning%5D%20fe71681b7adc4709871b2af69c765163/Untitled%201.png)

- å»¶è¿Ÿ(256 threads): 22ms

![Untitled](%5BCUDA%20Learning%5D%20fe71681b7adc4709871b2af69c765163/Untitled%202.png)

- å»¶è¿Ÿï¼ˆåŸå§‹ç‰ˆæœ¬ï¼‰ï¼š711 ms

---

- ä¸ä»…ç”¨æ›´å¤šçš„threadï¼Œä¹ŸåŒæ—¶è°ƒç”¨æ›´å¤šçš„blockè¿›è¡Œè®¡ç®—
    - ä¿®æ”¹add_kernelè®©æ¯ä¸ªthreadåªæ˜¯è¿›è¡Œä¸€ä¸ªå°å°çš„åŠ æ³•
    
    ```jsx
      3 __global__ void add_kernel(float *x, float *y, float *out, int n){
      4     int tid = blockIdx.x * blockDim.x + threadIdx.x;
      5
      6      if (tid < n) {  // due to N is not divisible by block_size, some blocks need to run empty
      7         out[tid] = x[tid] + y[tid];
      8     }
      9 }
    ```
    
    - ä¿®æ”¹Kernel Launchingçš„é…ç½®
    
    ```jsx
     37     int block_size = 256;
     38     int grid_size = (N+block_size)/block_size;
     39     add_kernel<<<grid_size, block_size>>>(cuda_x, cuda_y, cuda_out, N);
    ```
    

![Untitled](%5BCUDA%20Learning%5D%20fe71681b7adc4709871b2af69c765163/Untitled%203.png)

### 4. å¤šçº¿ç¨‹åŸç†ï¼š

- GPU ä¸Šä¸€èˆ¬åŒ…å«å¾ˆå¤šæµå¼å¤„ç†å™¨ SMï¼ˆStream Processorï¼Œæ¯”å¦‚V100å°±æœ‰80ä¸ªSMï¼ŒSMä¸­åŒ…å«äº†CUDA Coreï¼‰ï¼ŒSMå¯ä»¥çœ‹åšæ˜¯**åŸºæœ¬è®¡ç®—å•å…ƒ**ï¼Œå…¶ä¸­åˆ‡åˆ†æˆäº†è‹¥å¹²ä¸ªGridï¼Œæ¯ä¸ªGridä¸­åŒ…å«äº†è‹¥å¹²ä¸ªçº¿ç¨‹å—ï¼ˆBlockï¼Œæ¯”å¦‚65536ï¼‰ï¼Œæ¯ä¸ªçº¿ç¨‹å—åŒ…å«äº†è‹¥å¹²çº¿ç¨‹ï¼ˆThreadï¼Œå¦‚512ï¼‰ã€‚
    - Threadè®¡ç®—çš„åŸºæœ¬å•ä½ï¼Œä¸€ä¸ªCUDA Kernelï¼ˆworkloadï¼‰å¯ä»¥è¢«å¤šä¸ªThreadï¼ˆå®é™…çš„ç¡¬ä»¶å•å…ƒç®—åŠ›æŠ½è±¡ï¼‰æ¥æ‰§è¡Œ
    - Blockï¼šç”±å¤šä¸ªThreadç»„æˆï¼ŒåŒä¸€ä¸ªblockä¸­çš„threadså¯ä»¥äº’ç›¸åŒæ­¥ï¼Œå¹¶ä¸”å¯ä»¥è®¿é—®Shared Memory
    - Gridï¼šå¤šä¸ªBlockså¯ä»¥ç»„æˆä¸€ä¸ªGrid
    - **æ³¨æ„ï¼š**Blockå’ŒThreadsçš„æ’å¸ƒæ–¹å¼å¯ä»¥æ˜¯1-Dï¼Œ2-Dï¼Œ3-Dçš„
- çº¿ç¨‹å”¯ä¸€æ ‡è¯†ç¼–å·ï¼Œè®¡ç®—æ–¹å¼å’Œblock/threadçš„dimensionæ•°ç›®æœ‰å…³
    - æ¯”å¦‚Gridä¸€ç»´ï¼ŒBlockä¸ºäºŒç»´ï¼š
        
        ```jsx
        int threadId = blockIdx.x * blockDim.x * blockDim.y + 
                      threadIdx.y * blockDim.x + threadIdx.x;  
        ```
        
- Warpï¼šç”¨æ¥æ‰§è¡ŒåŒä¸€ä¸ªæŒ‡ä»¤çš„ä¸€ç»„threadï¼ˆSIMDï¼‰ï¼Œå…¸å‹å¤§å°ä¸º32
- ç»™äº†ä¸€ä¸ªæ‰“å°çº¿ç¨‹IDçš„exampleæ¥äº†è§£æœºåˆ¶ï¼š  `./print_id.cu`
    - å‡†å¤‡äº†128ä¸ªthread
    - è®¾ç½®warp_sizeä¸º32ï¼Œnum_threadsä¸º64ï¼Œnum_blocksä¸º2
    - é¢„å…ˆmallocæ¯ä¸ªarrayæœ‰128ä¸ªintå˜é‡
    - åœ¨where_is_my_idä¸­è¯»å–å†…å»ºå˜é‡çš„å€¼ï¼ˆthreadIdx, blockIdxï¼‰ï¼Œèµ‹å€¼ç»™warpä¸calc_threadç­‰æ•°ç»„ï¼Œä¸¢å›æ¥
    - **æ‰“å°å‡ºæ¥çš„ç»“æœå¯çŸ¥ï¼š**
        - block â†’ warps â†’ threads
- CUDAçš„å±‚æ¬¡ç»“æ„ï¼š
    - 3å±‚ï¼šGrid â†’ Block â†’ Thread (Warpæ˜¯ä¸€ä¸ªè½¯ä»¶æ¦‚å¿µï¼Œå¯ä»¥åœ¨çº¿ç¨‹è°ƒåº¦çš„è¿‡ç¨‹ä¸­åŠ¨æ€ç»„æˆæˆæ–°çš„thread)ï¼Œä¸€ä¸ª3ç»´çš„Exampleï¼š
        
        ![Untitled](%5BCUDA%20Learning%5D%20fe71681b7adc4709871b2af69c765163/Untitled%204.png)
        
    - åœ¨æ¯æ¬¡è°ƒç”¨CUDA Kernelçš„æ—¶å€™ï¼Œéƒ½ä¼šå®ä¾‹åŒ–ä¸€ä¸ªæ–°çš„Gridï¼Œå…¶ä¸­Blockç­‰sizeçš„å¤§å°å¯ä»¥ç”¨blockDimçš„å˜é‡è¿›è¡Œé…ç½®ã€‚
    
    ```jsx
    #define CEIL_DIV(M, N) (((M) + (N)-1) / (N))  // M+N/Nè¡¨ç¤ºCeilï¼Œåˆ†å­ä¸Šé¢å¤–-1
    
    dim3 gridDim(CEIL_DIV(M, 32), CEIL_DIV(N, 32));  // CEIL_DIV å‘ä¸Šå–æ•´çš„é™¤æ³•
    // 32 * 32 = 1024 thread per block
    dim3 blockDim(32, 32);
    ```
    

- ä»¥ä¸‹æ˜¯è¿›è¡Œä¸€ä¸ªæœ´ç´ çš„GEMMå®ç°çš„é…ç½®æ–¹å¼  `simple_matmul.cu`
    - çŸ©é˜µ $A \in [M,K]$
    - çŸ©é˜µ $B \in [K,N]$
    - CPUçš„ä¸‰å±‚å¾ªç¯è®¡ç®—ï¼Œä½œä¸ºReferenceï¼š `sgemm_naive_cpu`
        - M,N,Kå¾ªç¯ä¸‰è½®; A[m,k]*B[k,n]
            - åœ¨Kç»´åº¦ä¸Šreduce sumèµ·æ¥ï¼Œèµ‹å€¼ç»™è¾“å‡ºçŸ©é˜µçš„[m,n]
    - ä¸€ä¸ªæœ´ç´ çš„gemm kernel  `sgemm_naive_kernel`
        - å¦‚æœ(m<M, n<N)ï¼Œåœ¨Mï¼ŒNç»´åº¦ä¸Šparallelï¼Œä¸€å±‚å¾ªç¯K
            - äºŒç»´ï¼šblock*thread = ((M,32),32) = M

### References:

- [ğŸŒŸ]ä¸­æ–‡çš„ææ–™ï¼ŒPaddleJiTLabï¼š[CUDATutorial | Notebook (keter.top)](https://cuda.keter.top/)
    - https://github.com/PaddleJitLab/CUDATutorial
    - æ·±åº¦å­¦ä¹ åŸºç¡€çŸ¥è¯†ç›®å½• | Notebook (keter.top) æ ¼å¼å‚è€ƒäº†è¿™ä¸ªåšå®¢ï¼Œå‰ç«¯å¾ˆç¾è§‚
        - [CUDAæ‰§è¡Œæ¨¡å‹æ¦‚è¿° | Notebook (keter.top)](https://space.keter.top/docs/high_performance/CUDA%E7%BC%96%E7%A8%8B/CUDA%E6%89%A7%E8%A1%8C%E6%A8%A1%E5%9E%8B%E6%A6%82%E8%BF%B0)
- https://infinigence.feishu.cn/wiki/BtZLwOyYniUg80k1jPTcUANrn1f MixDQ Demoçš„æ„å»ºè¿‡ç¨‹
- [Tutorial 01: Say Hello to CUDA - CUDA Tutorial (cuda-tutorial.readthedocs.io)](https://cuda-tutorial.readthedocs.io/en/latest/tutorials/tutorial01/#:~:text=Tutorial%2001%3A%20Say%20Hello%20to%20CUDA%201%20Introduction,...%207%20Wrap%20up%20...%208%20Acknowledgments%20)
    - https://developer.nvidia.com/blog/even-easier-introduction-cuda/ çš„æ”¹è¿›ç‰ˆæœ¬ï¼Œç”¨ReadTheDocæ”¹å†™äº†ä¸¤ä¸ªç…è›‹çš„Example
- https://github.com/RussWong/CUDATutorial ä¸€ä¸ªå›½äººç»™äº†ä¸€ç³»åˆ—NNç›¸å…³çš„ä¾‹å­ï¼Œæœ€ååŒ…å«äº† fused kernel
- A simple short Slides: [CUDA.pdf (iitk.ac.in)](https://www.cse.iitk.ac.in/users/biswap/CASS18/CUDA.pdf)
- PDF on Github: ã€ŠCUDA Programming: A Developerâ€™s Guideã€‹ ä¹¦ç±
    - [cudaLearningMaterials_2/CUDAå¹¶è¡Œç¨‹åºè®¾è®¡-GPUç¼–ç¨‹æŒ‡å—-é«˜æ¸…æ‰«æ-ä¸­è‹±æ–‡/CUDA Programming A Developer's Guide to Parallel Computing with GPUs.pdf at master Â· SeventhBlue/cudaLearningMaterials_2 (github.com)](https://github.com/SeventhBlue/cudaLearningMaterials_2/blob/master/CUDA%E5%B9%B6%E8%A1%8C%E7%A8%8B%E5%BA%8F%E8%AE%BE%E8%AE%A1-GPU%E7%BC%96%E7%A8%8B%E6%8C%87%E5%8D%97-%E9%AB%98%E6%B8%85%E6%89%AB%E6%8F%8F-%E4%B8%AD%E8%8B%B1%E6%96%87/CUDA%20Programming%20A%20Developer's%20Guide%20to%20Parallel%20Computing%20with%20GPUs.pdf)
- çŸ¥ä¹Example: [CUDA ç¼–ç¨‹å°ç»ƒä¹ ï¼ˆç›®å½•ï¼‰ - çŸ¥ä¹ (zhihu.com)](https://zhuanlan.zhihu.com/p/365904031)